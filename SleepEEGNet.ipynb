{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SleepEEGNet 구현용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카세트\n",
    "path_eeg_fpz_cz_cs = '/home/whlee/0_research/DeepSleepNet_Implementation_in_Keras/data/eeg_fpz_cz.cs'\n",
    "path_eeg_pz_oz_cs = '/home/whlee/0_research/DeepSleepNet_Implementation_in_Keras/data/eeg_pz_oz.cs'\n",
    "# 텔레메트리\n",
    "path_eeg_fpz_cz_tm = '/home/whlee/0_research/DeepSleepNet_Implementation_in_Keras/data/eeg_fpz_cz.tm'\n",
    "path_eeg_pz_oz_tm = '/home/whlee/0_research/DeepSleepNet_Implementation_in_Keras/data/eeg_pz_oz.tm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from env import *\n",
    "\n",
    "project_path = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = DEVICES\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, losses, optimizers, metrics\n",
    "\n",
    "from models.deepsleepnet import DeepFeatureNet, DeepSleepNet\n",
    "from data_loader import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS 0\n",
      "ETA 0.0001\n",
      "BATCH_SIZE 20\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 0\n",
    "ETA = 1e-4\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "print('EPOCHS',EPOCHS)\n",
    "print('ETA',ETA)\n",
    "print('BATCH_SIZE',BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIME_STEP = 10\n",
    "SEQUENCE_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char2numY {'W': 0, 'N1': 1, 'N2': 2, 'N3': 3, 'REM': 4}\n",
      "char2numY {'W': 0, 'N1': 1, 'N2': 2, 'N3': 3, 'REM': 4, '<SOD>': 5, '<EOD>': 6} 7\n",
      "num2charY {0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'REM', 5: '<SOD>', 6: '<EOD>'}\n"
     ]
    }
   ],
   "source": [
    "classes = ['W', 'N1', \"N2\", \"N3\", \"REM\"]\n",
    "NUM_CLASSES = len(classes)\n",
    "\n",
    "char2numY = dict(zip(classes, range(len(classes))))\n",
    "print('char2numY',char2numY)\n",
    "\n",
    "char2numY['<SOD>'] = len(char2numY)\n",
    "char2numY['<EOD>'] = len(char2numY)\n",
    "print('char2numY', char2numY, len(char2numY))\n",
    "\n",
    "num2charY = dict(zip(char2numY.values(), char2numY.keys()))\n",
    "print('num2charY', num2charY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1977, 10, 3000, 1) (1977, 10)\n",
      "(1099, 10, 3000, 1) (1099, 10)\n",
      "(1140, 10, 3000, 1) (1140, 10)\n"
     ]
    }
   ],
   "source": [
    "# seq data loading\n",
    "_, _, _, _, _, _, x_seq_train, y_seq_train, x_seq_valid, y_seq_valid, x_seq_test, y_seq_test = dloader(path_eeg_fpz_cz_cs, seed=SEED, len_seq=SEQUENCE_LENGTH, return_sequences=True)\n",
    "\n",
    "print(x_seq_train.shape, y_seq_train.shape)\n",
    "print(x_seq_valid.shape, y_seq_valid.shape)\n",
    "print(x_seq_test.shape, y_seq_test.shape)\n",
    "\n",
    "x_seq_train /= np.max(x_seq_train)\n",
    "x_seq_valid /= np.max(x_seq_valid)\n",
    "x_seq_test /= np.max(x_seq_test)\n",
    "\n",
    "train_seq_dataset = tf.data.\\\n",
    "            Dataset.from_tensor_slices((x_seq_train, y_seq_train)).\\\n",
    "            batch(BATCH_SIZE).shuffle(len(x_seq_train))\n",
    "\n",
    "valid_seq_dataset = tf.data.\\\n",
    "            Dataset.from_tensor_slices((x_seq_valid, y_seq_valid)).\\\n",
    "            batch(BATCH_SIZE)\n",
    "\n",
    "test_seq_dataset = tf.data.\\\n",
    "            Dataset.from_tensor_slices((x_seq_test,y_seq_test)).\\\n",
    "            batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20, 3072])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(models.Model):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.c1 = models.Sequential([\n",
    "            layers.Conv1D(64, 50, strides=6, padding='same', activation=tf.nn.relu),\n",
    "            layers.MaxPool1D(8, 8, padding='same'),\n",
    "            \n",
    "            layers.Dropout(.5),\n",
    "            \n",
    "            layers.Conv1D(128, 8, strides=1, padding='same', activation=tf.nn.relu),\n",
    "            layers.Conv1D(128, 8, strides=1, padding='same', activation=tf.nn.relu),\n",
    "            layers.Conv1D(128, 8, strides=1, padding='same', activation=tf.nn.relu),\n",
    "            \n",
    "            layers.MaxPool1D(4, 4, padding='same'),\n",
    "        ])\n",
    "        \n",
    "        self.c2 = models.Sequential([\n",
    "            layers.Conv1D(64, 400, strides=50, padding='same', activation=tf.nn.relu),\n",
    "            layers.MaxPool1D(4, 4, padding='same'),\n",
    "            \n",
    "            layers.Dropout(.5),\n",
    "            \n",
    "            layers.Conv1D(128, 6, strides=1, padding='same', activation=tf.nn.relu),\n",
    "            layers.Conv1D(128, 6, strides=1, padding='same', activation=tf.nn.relu),\n",
    "            layers.Conv1D(128, 6, strides=1, padding='same', activation=tf.nn.relu),\n",
    "            \n",
    "            layers.MaxPool1D(2, 2, padding='same')\n",
    "        ])\n",
    "        \n",
    "        self.drop = layers.Dropout(.5)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        c1 = self.c1(inputs, training=training)\n",
    "        c1 = layers.Flatten()(c1)\n",
    "        c2 = self.c2(inputs, training=training)\n",
    "        c2 = layers.Flatten()(c2)\n",
    "        x = tf.concat([c1, c2], axis=-1)\n",
    "        x = self.drop(x, training=training)\n",
    "        return x\n",
    "        \n",
    "cnn = CNN()\n",
    "cnn(np.ones((BATCH_SIZE,3000,1),dtype=np.float32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([20, 10, 256]), TensorShape([20, 256]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(models.Model):\n",
    "    def __init__(self, cnn):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.cnn = cnn\n",
    "        self.lstm_f = layers.LSTM(128, return_sequences=True, return_state=True)\n",
    "        self.lstm_b = layers.LSTM(128, return_sequences=True, return_state=True, go_backwards=True)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = []\n",
    "        for i in range(inputs.shape[1]):\n",
    "            _x = cnn(inputs[:,i])\n",
    "            _x = tf.expand_dims(_x, axis=1)\n",
    "            x.append(_x)\n",
    "        x = tf.concat(x, axis=1)\n",
    "        f, fh, _ = self.lstm_f(x)\n",
    "        b, bh, _ = self.lstm_b(x)\n",
    "        x = tf.concat([f,b], axis=-1)\n",
    "        h = tf.concat([fh, bh], axis=-1)\n",
    "        return x, h\n",
    "        \n",
    "encoder = Encoder(cnn)\n",
    "encoder(np.ones((BATCH_SIZE, SEQUENCE_LENGTH, 3000, 1),dtype=np.float32))[0].shape,\\\n",
    "encoder(np.ones((BATCH_SIZE, SEQUENCE_LENGTH, 3000, 1),dtype=np.float32))[1].shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* attention function $f(\\cdot)$\n",
    "* attention probability $\\alpha_i$ : 각각의 hidden state의 중요도에 관한 것\n",
    "* scores와 hidden states를 곱해서 weighted combination $c_t$ 를 구함\n",
    "\n",
    "$$\n",
    "f(h_{t-1}, e_i ) = \\tanh (W_h h_{t-1} + W_e e_i)\n",
    "$$\n",
    "\n",
    "\\begin{align}\n",
    "\\alpha_i & = softmax(f(h_{t-1}, e_i)) \\approx {\\exp(f(h_{t-1}, e_i)) \\over \\sum_{j=1}^n \\exp(f(h_{t-1}, e_j))} \\\\\n",
    "i&\\in 1, 2, \\cdots, n,\n",
    "\\end{align}\n",
    "\n",
    "$$\n",
    "c_t = \\sum_{i=0}^n \\alpha_i e_i\n",
    "$$\n",
    "\n",
    "**이 때**\n",
    "* $\\alpha_i$ : hidden state의 part $i$에 대한 중요도\n",
    "* 즉, 매 time step $t$ 마다, attention layer 는 $f(\\cdot)$을 계산함\n",
    ":* encoder 의 hidden state $e_i$ 와 decoder의 hidden state $h_{t-1}$ 의 조합에 $\\tanh$ 씌운거\n",
    "* 그러고 나면, 이걸 softmax 에 넣어서, $n$개의 parts에 대해서 $\\alpha_i$를 계산함\n",
    "* 마지막으로, 모든 벡터 $e_i$와 그에 해당하는 $\\alpha_i$의 attention module $c_t$를 계산함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([20, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Attention(models.Model):\n",
    "    def __init__(self, latent):\n",
    "        super(Attention, self).__init__()\n",
    "        self.We = layers.Dense(latent)\n",
    "        self.Wh = layers.Dense(latent)\n",
    "        self.tanh = layers.Activation(tf.nn.tanh)\n",
    "        self.softmax = layers.Activation(tf.nn.softmax)\n",
    "        \n",
    "    def call(self, encoder_hidden, decoder_hidden, training=False):\n",
    "        WE = self.We(encoder_hidden)\n",
    "        decoder_hidden = tf.expand_dims(decoder_hidden, axis=1)\n",
    "        WH = self.Wh(decoder_hidden)\n",
    "        x = WE + WH\n",
    "        f = self.tanh(x)\n",
    "        alpha = self.softmax(f)\n",
    "        c = alpha * encoder_hidden\n",
    "        c = tf.reduce_sum(c, axis=1)\n",
    "        return c\n",
    "        \n",
    "attention = Attention(256)\n",
    "attention(\n",
    "    np.ones((BATCH_SIZE,SEQUENCE_LENGTH,256),dtype=np.float32), \n",
    "    np.ones((BATCH_SIZE, 256),dtype=np.float32)\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([20, 7]), TensorShape([20, 256]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Decoder(models.Model):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.lstm_f = layers.LSTM(128, return_sequences=True, return_state=True)\n",
    "        self.lstm_b = layers.LSTM(128, return_sequences=True, return_state=True, go_backwards=True)\n",
    "        self.attention = Attention(256)\n",
    "        self.classes = layers.Dense(7, activation=tf.nn.softmax)\n",
    "        \n",
    "    def call(self, decoder_input, prev_decoder_hidden, encoder_hidden, training=False):\n",
    "        c = self.attention(encoder_hidden, prev_decoder_hidden)\n",
    "        x = tf.concat([c, decoder_input], axis=-1)\n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "        f, fh, _ = self.lstm_f(x, training=training)\n",
    "        b, bh, _ = self.lstm_b(x, training=training)\n",
    "        h = tf.concat([fh, bh], axis=-1)\n",
    "        x = tf.concat([f, b], axis=-1)\n",
    "        prediction = self.classes(x)\n",
    "        prediction = tf.squeeze(prediction, axis=1)\n",
    "        return prediction, h\n",
    "        \n",
    "decoder = Decoder()\n",
    "decoder(\n",
    "    np.ones((BATCH_SIZE,NUM_CLASSES+2),dtype=np.float32), # decoder 에 입력\n",
    "    np.ones((BATCH_SIZE,256),dtype=np.float32), # 이전 단계 decoder hidden (첨에는 encoder마지막 놈의 hidden)\n",
    "    np.ones((BATCH_SIZE,SEQUENCE_LENGTH,256),dtype=np.float32) # 인코더 전체 시퀀스 output\n",
    ")[0].shape,\\\n",
    "decoder(\n",
    "    np.ones((BATCH_SIZE,NUM_CLASSES+2),dtype=np.float32), # decoder 에 입력\n",
    "    np.ones((BATCH_SIZE,256),dtype=np.float32), # 이전 단계 decoder hidden (첨에는 encoder마지막 놈의 hidden)\n",
    "    np.ones((BATCH_SIZE,SEQUENCE_LENGTH,256),dtype=np.float32) # 인코더 전체 시퀀스 output\n",
    ")[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = losses.CategoricalCrossentropy()\n",
    "acc_object = metrics.CategoricalAccuracy()\n",
    "loss = metrics.Mean()\n",
    "acc = metrics.Mean()\n",
    "\n",
    "varlist = encoder.trainable_variables+decoder.trainable_variables\n",
    "opt = optimizers.Adam(learning_rate=ETA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs):\n",
    "    _X, _y = inputs\n",
    "    # 어차피 정해진 길이 SEQUENCE_LENGTH 만큼만 할 건데 SOD, EOD 필요 있나 싶음\n",
    "#     _y = np.insert(_y, 0, char2numY.get('<SOD>'), axis=1)\n",
    "#     _y = np.insert(_y, _y.shape[-1], char2numY.get('<EOD>'), axis=1)\n",
    "    _y = tf.one_hot(_y, depth=NUM_CLASSES+2)\n",
    "    \n",
    "    _loss = 0.\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        encoder_output, hidden_state = encoder(_X, training=True)\n",
    "        \n",
    "        decoder_input = tf.one_hot(char2numY.get('<SOD>'), depth=NUM_CLASSES+2)\n",
    "        decoder_input = tf.multiply(\n",
    "            tf.ones((_X.shape[0],NUM_CLASSES+2),dtype=tf.float32),\n",
    "            decoder_input) # <SOD> 로 시작\n",
    "\n",
    "        for t in range(SEQUENCE_LENGTH):\n",
    "            pred, hidden_state = decoder(decoder_input, hidden_state, encoder_output, training=True)\n",
    "            _loss += loss_object(_y[:,t], pred)\n",
    "            acc.update_state(acc_object(_y[:,t], pred))\n",
    "            loss.update_state(_loss)\n",
    "            decoder_input = _y[:,t]\n",
    "\n",
    "    grads = tape.gradient(_loss, varlist)\n",
    "    opt.apply_gradients(list(zip(grads, varlist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss = metrics.Mean()\n",
    "valid_acc = metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_step(inputs):\n",
    "    _X, _y = inputs\n",
    "    _y = tf.one_hot(_y, depth=NUM_CLASSES+2)\n",
    "    \n",
    "    _loss = 0.\n",
    "    \n",
    "    encoder_output, hidden_state = encoder(_X, training=False)\n",
    "\n",
    "    decoder_input = tf.one_hot(char2numY.get('<SOD>'), depth=NUM_CLASSES+2)\n",
    "    decoder_input = tf.multiply(\n",
    "        tf.ones((_X.shape[0],NUM_CLASSES+2),dtype=tf.float32),\n",
    "        decoder_input) # <SOD> 로 시작\n",
    "\n",
    "    for t in range(SEQUENCE_LENGTH):\n",
    "        pred, hidden_state = decoder(decoder_input, hidden_state, encoder_output, training=False)\n",
    "        _loss += loss_object(_y[:,t], pred)\n",
    "        valid_acc.update_state(acc_object(_y[:,t], pred))\n",
    "        valid_loss.update_state(_loss)\n",
    "        decoder_input = _y[:,t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = metrics.Mean()\n",
    "test_acc = metrics.Mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(inputs):\n",
    "    _X, _y = inputs\n",
    "    _y = tf.one_hot(_y, depth=NUM_CLASSES+2)\n",
    "    \n",
    "    _loss = 0.\n",
    "    \n",
    "    encoder_output, hidden_state = encoder(_X, training=False)\n",
    "\n",
    "    decoder_input = tf.one_hot(char2numY.get('<SOD>'), depth=NUM_CLASSES+2)\n",
    "    decoder_input = tf.multiply(\n",
    "        tf.ones((_X.shape[0],NUM_CLASSES+2),dtype=tf.float32),\n",
    "        decoder_input) # <SOD> 로 시작\n",
    "\n",
    "    for t in range(SEQUENCE_LENGTH):\n",
    "        pred, hidden_state = decoder(decoder_input, hidden_state, encoder_output, training=False)\n",
    "        _loss += loss_object(_y[:,t], pred)\n",
    "        test_acc.update_state(acc_object(_y[:,t], pred))\n",
    "        test_loss.update_state(_loss)\n",
    "        decoder_input = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_time = time.time()\n",
    "\n",
    "# min_loss = 1e10\n",
    "# min_epoch = 0\n",
    "\n",
    "# for e in range(EPOCHS):\n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     for i,x in enumerate(train_seq_dataset):\n",
    "#         train_step(x)\n",
    "        \n",
    "#     for i,x in enumerate(valid_seq_dataset):\n",
    "#         valid_step(x)\n",
    "    \n",
    "#     ipd.clear_output(wait=True)\n",
    "#     print(f\"{e+1}/{EPOCHS}, loss={loss.result():.8f}, train acc={acc.result()*100:.2f}%,\")\n",
    "#     print(f\"validation: loss={valid_loss.result():.8f}, acc={valid_acc.result()*100:.2f}%, {time.time()-start_time:.2f} sec/epoch, totally {time.time()-total_time:.2f} seconds\")\n",
    "#     print(f\"\\tbest valid loss = {min_loss:.8f} at epoch-{min_epoch}\")\n",
    "    \n",
    "#     if min_loss > valid_loss.result():\n",
    "#         min_loss = valid_loss.result()\n",
    "#         min_epoch = e\n",
    "#         # BEST MODEL만 저장\n",
    "# #         encoder.save_weights(f\"../weights/sleepeegnet/encoder-{SEED}\")\n",
    "# #         decoder.save_weights(f\"../weights/sleepeegnet/decoder-{SEED}\")\n",
    "    \n",
    "#     loss.reset_states()\n",
    "#     acc.reset_states()\n",
    "#     valid_loss.reset_states()\n",
    "#     valid_acc.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f87d8f83b90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.load_weights(f\"../weights/sleepeegnet/encoder-{SEED}\")\n",
    "decoder.load_weights(f\"../weights/sleepeegnet/decoder-{SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: loss=3.53461695, acc=81.93%, 11.69 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i, x in enumerate(test_seq_dataset):\n",
    "    test_step(x)\n",
    "    ipd.clear_output(wait=True)\n",
    "    print(i)\n",
    "ipd.clear_output(wait=True)\n",
    "print(f\"test: loss={test_loss.result():.8f}, acc={test_acc.result()*100:.2f}%, {time.time()-start_time:.2f} seconds\")\n",
    "test_loss.reset_states()\n",
    "test_acc.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
